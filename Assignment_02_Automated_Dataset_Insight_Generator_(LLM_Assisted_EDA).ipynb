{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEPEbRTts9VVECczETzVyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulHipparkar/DM-Assignment-02-Automated-Dataset-Insight-Generator-LLM-Assisted-EDA-/blob/main/Assignment_02_Automated_Dataset_Insight_Generator_(LLM_Assisted_EDA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "\n",
        "In our in-class activity, we practiced “getting to know your data” by loading a dataset, checking its structure, computing descriptive statistics, creating plots, and writing short interpretations about patterns and data quality. This assignment extends that workflow: you will build a Python system that can analyze any dataset a user uploads and automatically produce a clear set of useful data insights.\n",
        "\n",
        "Your system will accept a CSV file as input (required). It may also accept an optional schema / data dictionary file that describes the columns (e.g., name, type, meaning, units, allowed values, missing-value codes). Your system must still run and produce results even if the schema file is not provided.\n",
        "\n",
        "You have full access to GenAI tools, including cloud-based models (e.g., ChatGPT, Gemini, Claude) and local/open-source LLMs (e.g., Mistral, DeepSeek, Llama, or similar). You may use GenAI for brainstorming, code assistance, and generating narrative insight. However, you must document your GenAI usage by including a prompt/response log in your repository, and you remain responsible for verifying correctness (i.e., do not present unsupported or hallucinated conclusions as facts)."
      ],
      "metadata": {
        "id": "EWPFla6smFdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Team Overview\n",
        "\n",
        "**Team Members : Rahul Hipparkar, Himanshu Jain**"
      ],
      "metadata": {
        "id": "Sz3uzRE7K8lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "QPdt0zbxmQ0x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-SY_svkimE9r"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google import genai\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Datasets"
      ],
      "metadata": {
        "id": "9TerIoYcnEsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O wine_red.csv \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\""
      ],
      "metadata": {
        "id": "JZO9tg9i86N_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = sns.load_dataset('tips')     # development dataset\n",
        "df_unseen = pd.read_csv(\"wine_red.csv\", sep=\";\")  # unseen dataset"
      ],
      "metadata": {
        "id": "XWdnEgP4nIPF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intializing GEMINI"
      ],
      "metadata": {
        "id": "9Cz0HyF_oxWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "client = genai.Client(api_key=userdata.get('GEMINI_API_KEY'))"
      ],
      "metadata": {
        "id": "6NqLJnm7o0Pm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"logs\", exist_ok=True)"
      ],
      "metadata": {
        "id": "v90xQnMPq17V"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = client.models.list()\n",
        "for m in models:\n",
        "    # Some SDK versions expose fields slightly differently; print what you have\n",
        "    print(getattr(m, \"name\", None), getattr(m, \"supported_generation_methods\", None))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyjf2vrppskL",
        "outputId": "8aad8475-6ba5-404b-ec9a-7c1414d6e730"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-2.5-flash None\n",
            "models/gemini-2.5-pro None\n",
            "models/gemini-2.0-flash None\n",
            "models/gemini-2.0-flash-001 None\n",
            "models/gemini-2.0-flash-exp-image-generation None\n",
            "models/gemini-2.0-flash-lite-001 None\n",
            "models/gemini-2.0-flash-lite None\n",
            "models/gemini-exp-1206 None\n",
            "models/gemini-2.5-flash-preview-tts None\n",
            "models/gemini-2.5-pro-preview-tts None\n",
            "models/gemma-3-1b-it None\n",
            "models/gemma-3-4b-it None\n",
            "models/gemma-3-12b-it None\n",
            "models/gemma-3-27b-it None\n",
            "models/gemma-3n-e4b-it None\n",
            "models/gemma-3n-e2b-it None\n",
            "models/gemini-flash-latest None\n",
            "models/gemini-flash-lite-latest None\n",
            "models/gemini-pro-latest None\n",
            "models/gemini-2.5-flash-lite None\n",
            "models/gemini-2.5-flash-image None\n",
            "models/gemini-2.5-flash-preview-09-2025 None\n",
            "models/gemini-2.5-flash-lite-preview-09-2025 None\n",
            "models/gemini-3-pro-preview None\n",
            "models/gemini-3-flash-preview None\n",
            "models/gemini-3-pro-image-preview None\n",
            "models/nano-banana-pro-preview None\n",
            "models/gemini-robotics-er-1.5-preview None\n",
            "models/gemini-2.5-computer-use-preview-10-2025 None\n",
            "models/deep-research-pro-preview-12-2025 None\n",
            "models/embedding-001 None\n",
            "models/text-embedding-004 None\n",
            "models/gemini-embedding-001 None\n",
            "models/aqa None\n",
            "models/imagen-4.0-generate-preview-06-06 None\n",
            "models/imagen-4.0-ultra-generate-preview-06-06 None\n",
            "models/imagen-4.0-generate-001 None\n",
            "models/imagen-4.0-ultra-generate-001 None\n",
            "models/imagen-4.0-fast-generate-001 None\n",
            "models/veo-2.0-generate-001 None\n",
            "models/veo-3.0-generate-001 None\n",
            "models/veo-3.0-fast-generate-001 None\n",
            "models/veo-3.1-generate-preview None\n",
            "models/veo-3.1-fast-generate-preview None\n",
            "models/gemini-2.5-flash-native-audio-latest None\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025 None\n",
            "models/gemini-2.5-flash-native-audio-preview-12-2025 None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"Say hello in one sentence.\"\n",
        ")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uXQw06FqCFX",
        "outputId": "6d51c605-7552-416d-a7bb-84597fd1d9c9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I hope you are having a wonderful day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to utilize Gemini to do EDA and generate insights"
      ],
      "metadata": {
        "id": "g-G6Lv_lnMlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MISSING_CODES = [-999, 9999, -1, \"NA\", \"N/A\", \"na\", \"null\", \"NULL\", \"unknown\", \"Unknown\", \"\"]\n",
        "\n",
        "def run_eda_with_gemini(df, run_name, model=\"gemini-flash-latest\"):\n",
        "    outdir = Path(\"output\") / run_name\n",
        "    plots_dir = outdir / \"plots\"\n",
        "    tables_dir = outdir / \"tables\"\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
        "    tables_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Clean missing codes\n",
        "    dfx = df.copy()\n",
        "    dfx.replace(MISSING_CODES, np.nan, inplace=True)\n",
        "\n",
        "    #Overview + quality\n",
        "    overview = {\n",
        "        \"rows\": int(dfx.shape[0]),\n",
        "        \"cols\": int(dfx.shape[1]),\n",
        "        \"columns\": dfx.columns.tolist(),\n",
        "        \"inferred_types\": {c: str(dfx[c].dtype) for c in dfx.columns},\n",
        "        \"duplicates\": int(dfx.duplicated().sum()),\n",
        "    }\n",
        "\n",
        "    missing_tbl = (\n",
        "        dfx.isna().sum().to_frame(\"missing_count\")\n",
        "        .assign(missing_pct=lambda x: (x[\"missing_count\"]/len(dfx)*100).round(2))\n",
        "        .sort_values(\"missing_pct\", ascending=False)\n",
        "        .reset_index().rename(columns={\"index\":\"column\"})\n",
        "    )\n",
        "    missing_tbl.to_csv(tables_dir / \"missing_summary.csv\", index=False)\n",
        "\n",
        "    nunique = dfx.nunique(dropna=True)\n",
        "    one_value_cols = nunique[nunique <= 1].index.tolist()\n",
        "    high_missing_cols = missing_tbl.loc[missing_tbl[\"missing_pct\"] > 40, \"column\"].tolist()\n",
        "\n",
        "    quality = {\"one_value_cols\": one_value_cols, \"high_missing_cols\": high_missing_cols}\n",
        "\n",
        "    # Categorical summary (1 column)\n",
        "    cat_cols = dfx.select_dtypes(exclude=\"number\").columns.tolist()\n",
        "    cat_col, cat_tbl = None, None\n",
        "    if cat_cols:\n",
        "        # choose a moderate-cardinality categorical column\n",
        "        candidates = []\n",
        "        for c in cat_cols:\n",
        "            u = dfx[c].nunique(dropna=True)\n",
        "            if 2 <= u <= 50:\n",
        "                candidates.append((abs(u-10), u, c))\n",
        "        cat_col = sorted(candidates)[0][2] if candidates else cat_cols[0]\n",
        "        vc = dfx[cat_col].astype(\"string\").value_counts(dropna=True)\n",
        "        total = dfx[cat_col].notna().sum()\n",
        "        cat_tbl = (\n",
        "            vc.head(20).to_frame(\"count\")\n",
        "            .assign(pct=lambda x: (x[\"count\"]/total*100).round(2))\n",
        "            .reset_index().rename(columns={\"index\":\"value\"})\n",
        "        )\n",
        "        cat_tbl.to_csv(tables_dir / \"categorical_freq.csv\", index=False)\n",
        "\n",
        "    # Numeric stats (≥2 if available) + outliers (IQR)\n",
        "    num_cols = dfx.select_dtypes(include=\"number\").columns.tolist()\n",
        "    num_rows = []\n",
        "    for c in num_cols:\n",
        "        s = dfx[c].dropna()\n",
        "        if len(s) == 0:\n",
        "            continue\n",
        "        q1, q3 = s.quantile([0.25, 0.75])\n",
        "        iqr = float(q3 - q1)\n",
        "        lo, hi = float(q1 - 1.5*iqr), float(q3 + 1.5*iqr)\n",
        "        outlier_pct = float(((s < lo) | (s > hi)).mean() * 100)\n",
        "        mode_val = s.mode()\n",
        "        mode_val = float(mode_val.iloc[0]) if len(mode_val) else np.nan\n",
        "\n",
        "        num_rows.append({\n",
        "            \"column\": c,\n",
        "            \"min\": float(s.min()), \"max\": float(s.max()),\n",
        "            \"mean\": float(s.mean()), \"median\": float(s.median()),\n",
        "            \"mode\": mode_val,\n",
        "            \"std\": float(s.std(ddof=1)) if len(s) > 1 else 0.0,\n",
        "            \"iqr\": iqr,\n",
        "            \"outlier_low\": lo, \"outlier_high\": hi,\n",
        "            \"outlier_pct\": round(outlier_pct, 2),\n",
        "            \"n_nonnull\": int(len(s)),\n",
        "        })\n",
        "\n",
        "    num_tbl = pd.DataFrame(num_rows).sort_values(\"n_nonnull\", ascending=False)\n",
        "    num_tbl.to_csv(tables_dir / \"numeric_summary.csv\", index=False)\n",
        "\n",
        "    # Make ≥5 plots\n",
        "    plots = []\n",
        "    def savefig(path):\n",
        "        plt.savefig(path, bbox_inches=\"tight\"); plt.close()\n",
        "        plots.append(str(path))\n",
        "\n",
        "    # 1 histogram\n",
        "    if num_cols:\n",
        "        c = num_cols[0]\n",
        "        plt.figure()\n",
        "        sns.histplot(dfx[c].dropna(), bins=30)\n",
        "        plt.title(f\"Histogram: {c}\"); plt.xlabel(c); plt.ylabel(\"Count\")\n",
        "        savefig(plots_dir / f\"hist_{c}.png\")\n",
        "\n",
        "    # 2 boxplot\n",
        "    if len(num_cols) > 1:\n",
        "        c = num_cols[1]\n",
        "        plt.figure()\n",
        "        sns.boxplot(x=dfx[c])\n",
        "        plt.title(f\"Boxplot: {c}\"); plt.xlabel(c); plt.ylabel(\"Value\")\n",
        "        savefig(plots_dir / f\"box_{c}.png\")\n",
        "\n",
        "    # 3 bar chart\n",
        "    if cat_cols:\n",
        "        c = cat_cols[0]\n",
        "        vc = dfx[c].astype(\"string\").value_counts(dropna=True).head(10)\n",
        "        plt.figure()\n",
        "        vc.plot(kind=\"bar\")\n",
        "        plt.title(f\"Top 10 Categories: {c}\"); plt.xlabel(c); plt.ylabel(\"Count\")\n",
        "        savefig(plots_dir / f\"bar_{c}.png\")\n",
        "\n",
        "    # 4 scatter\n",
        "    if len(num_cols) >= 2:\n",
        "        x, y = num_cols[0], num_cols[1]\n",
        "        plt.figure()\n",
        "        sns.scatterplot(x=dfx[x], y=dfx[y])\n",
        "        plt.title(f\"Scatter: {x} vs {y}\"); plt.xlabel(x); plt.ylabel(y)\n",
        "        savefig(plots_dir / f\"scatter_{x}_vs_{y}.png\")\n",
        "\n",
        "    # 5 correlation heatmap\n",
        "    if len(num_cols) >= 2:\n",
        "        plt.figure(figsize=(7,6))\n",
        "        sns.heatmap(dfx[num_cols].corr(numeric_only=True), annot=False)\n",
        "        plt.title(\"Correlation Heatmap (Numeric Columns)\")\n",
        "        plt.xlabel(\"Columns\"); plt.ylabel(\"Columns\")\n",
        "        savefig(plots_dir / \"corr_heatmap.png\")\n",
        "\n",
        "    # fallback if <5\n",
        "    if len(plots) < 5:\n",
        "        miss = dfx.isna().mean().mul(100).sort_values(ascending=False).head(20)\n",
        "        plt.figure(figsize=(8,4))\n",
        "        miss.plot(kind=\"bar\")\n",
        "        plt.title(\"Top Missingness by Column (%)\")\n",
        "        plt.xlabel(\"Column\"); plt.ylabel(\"Missing %\")\n",
        "        savefig(plots_dir / \"missingness_top.png\")\n",
        "\n",
        "    # Gemini insights from computed facts only\n",
        "    facts_for_gemini = {\n",
        "        \"overview\": overview,\n",
        "        \"quality_checks\": quality,\n",
        "        \"missing_top10\": missing_tbl.head(10).to_dict(orient=\"records\"),\n",
        "        \"categorical_summary\": None if cat_tbl is None else {\n",
        "            \"column\": cat_col,\n",
        "            \"top_values\": cat_tbl.head(10).to_dict(orient=\"records\"),\n",
        "        },\n",
        "        \"numeric_summary_top\": num_tbl.head(10).to_dict(orient=\"records\"),\n",
        "        \"plots_saved\": plots,\n",
        "    }\n",
        "\n",
        "    client = genai.Client(api_key=userdata.get('GEMINI_API_KEY'))\n",
        "    prompt = f\"\"\"\n",
        "You are an EDA assistant.\n",
        "\n",
        "STRICT RULES:\n",
        "- Use ONLY the numbers/columns in FACTS_JSON.\n",
        "- Do NOT invent any values.\n",
        "- Output:\n",
        "  1) 5–10 bullet insights (each must mention a specific column + a number from the facts)\n",
        "  2) 1 short limitations/bias note (missingness, sampling, coverage, etc.)\n",
        "\n",
        "FACTS_JSON:\n",
        "{json.dumps(facts_for_gemini, indent=2)}\n",
        "\"\"\"\n",
        "    resp = client.models.generate_content(model=model, contents=prompt)\n",
        "    insights_text = resp.text\n",
        "\n",
        "    # Write report.md\n",
        "    report = []\n",
        "    report.append(f\"# Automated EDA Report — {run_name}\\n\")\n",
        "    report.append(\"## Dataset Overview\\n\")\n",
        "    report.append(f\"- Rows: **{overview['rows']}**\\n- Columns: **{overview['cols']}**\\n- Duplicates: **{overview['duplicates']}**\\n\")\n",
        "\n",
        "    report.append(\"\\n### Inferred Types (first 15)\\n\")\n",
        "    for c in overview[\"columns\"][:15]:\n",
        "        report.append(f\"- {c}: {overview['inferred_types'][c]}\\n\")\n",
        "\n",
        "    report.append(\"\\n### Missing Value Summary (Top 10)\\n\")\n",
        "    report.append(missing_tbl.head(10).to_markdown(index=False))\n",
        "\n",
        "    report.append(\"\\n## Basic Data Quality Checks\\n\")\n",
        "    report.append(f\"- Columns with one value: {quality['one_value_cols']}\\n\")\n",
        "    report.append(f\"- High-missing columns (>40%): {quality['high_missing_cols']}\\n\")\n",
        "\n",
        "    report.append(\"\\n## Descriptive Statistics\\n\")\n",
        "    if cat_tbl is not None:\n",
        "        report.append(f\"### Categorical: `{cat_col}` (Top values)\\n\")\n",
        "        report.append(cat_tbl.head(10).to_markdown(index=False))\n",
        "    else:\n",
        "        report.append(\"No categorical columns detected.\\n\")\n",
        "\n",
        "    report.append(\"\\n### Numeric (Top rows)\\n\")\n",
        "    if not num_tbl.empty:\n",
        "        report.append(num_tbl.head(10).to_markdown(index=False))\n",
        "    else:\n",
        "        report.append(\"No numeric columns detected.\\n\")\n",
        "\n",
        "    report.append(\"\\n## Visualizations (saved files)\\n\")\n",
        "    for p in plots:\n",
        "        report.append(f\"- {p}\\n\")\n",
        "\n",
        "    report.append(\"\\n## Insights + Limitations (Gemini)\\n\")\n",
        "    report.append(insights_text)\n",
        "\n",
        "    (outdir / \"report.md\").write_text(\"\\n\".join(report), encoding=\"utf-8\")\n",
        "\n",
        "    # ---- (H) Save log for this run\n",
        "    log_path = Path(\"logs\") / f\"genai_log_{run_name}.md\"\n",
        "    log_path.write_text(\n",
        "        \"## Tool used\\nGemini API via google-genai\\n\\n\"\n",
        "        f\"## Prompt\\n```text\\n{prompt[:3500]}\\n```\\n\\n\"\n",
        "        f\"## Response\\n```text\\n{insights_text[:3500]}\\n```\\n\",\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "\n",
        "    return str(outdir / \"report.md\")\n"
      ],
      "metadata": {
        "id": "ByhgdVZFnXdn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "8ReiHKaunuo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_report = run_eda_with_gemini(df_train, run_name=\"dev_training_dataset\")\n",
        "dev_report"
      ],
      "metadata": {
        "id": "BSW6cBJrn66W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8701a69-cc62-4007-ecd8-b283dd8e0314"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output/dev_training_dataset/report.md'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_report = run_eda_with_gemini(df_unseen, run_name=\"unseen_inference_dataset\")\n",
        "unseen_report"
      ],
      "metadata": {
        "id": "jqVKhvkJ6Cut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f12f6051-1f68-4791-c0bf-b2ff1ee197f1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output/unseen_inference_dataset/report.md'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}